{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59dada",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43aa881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, levene, ranksums\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import math\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import importlib\n",
    "import config \n",
    "importlib.reload(config)\n",
    "from config import BIN_SIZE as bin_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499beba",
   "metadata": {},
   "source": [
    "# Loading Samples (262 without Holdout-Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d749d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for 262 samples:\n",
      "['EE87789', 'EE87790', 'EE87791', 'EE87792', 'EE87793', 'EE87794', 'EE87795', 'EE87796', 'EE87797', 'EE87798', 'EE87799', 'EE87800', 'EE87801', 'EE87802', 'EE87803', 'EE87804', 'EE87805', 'EE87806', 'EE87807', 'EE87809', 'EE87810', 'EE88325', 'EE85727', 'EE85730', 'EE85731', 'EE85732', 'EE85733', 'EE85734', 'EE85737', 'EE85739', 'EE85741', 'EE85743', 'EE85746', 'EE85749', 'EE85750', 'EE85752', 'EE85753', 'EE86234', 'EE86255', 'EE86259', 'EE87865', 'EE87866', 'EE87867', 'EE87868', 'EE87869', 'EE87870', 'EE87871', 'EE87872', 'EE87873', 'EE87874', 'EE87875', 'EE87876', 'EE87877', 'EE87878', 'EE87879', 'EE87880', 'EE87881', 'EE87882', 'EE87883', 'EE87884', 'EE87885', 'EE87886', 'EE87887', 'EE87888', 'EE87889', 'EE87890', 'EE87891', 'EE87896', 'EE87897', 'EE87898', 'EE87899', 'EE87900', 'EE87901', 'EE87902', 'EE87903', 'EE87904', 'EE87905', 'EE87906', 'EE87907', 'EE87908', 'EE87909', 'EE87910', 'EE87911', 'EE87912', 'EE87913', 'EE87914', 'EE87915', 'EE87916', 'EE87917', 'EE87918', 'EE87919', 'EE86268', 'EE86270', 'EE86271', 'EE86272', 'EE86273', 'EE88290', 'EE88291', 'EE88292', 'EE88293', 'EE88294', 'EE88295', 'EE88296', 'EE88297', 'EE88298', 'EE88299', 'EE88300', 'EE88301', 'EE88302', 'EE88303', 'EE88304', 'EE88305', 'EE88306', 'EE88307', 'EE88308', 'EE88309', 'EE88310', 'EE88311', 'EE88312', 'EE88313', 'EE88314', 'EE88315', 'EE88316', 'EE88317', 'EE88318', 'EE88319', 'EE88320', 'EE88321', 'EE88322', 'EE88323', 'EE88324', 'EE85898', 'EE85904', 'EE85905', 'EE85908', 'EE85918', 'EE85928', 'EE85936', 'EE85937', 'EE85941', 'EE85959', 'EE85963', 'EE85970', 'EE85971', 'EE85980', 'EE85985', 'EE85987', 'EE85988', 'EE86275', 'EE86276', 'EE87945', 'EE87946', 'EE87920', 'EE87921', 'EE87922', 'EE87923', 'EE87924', 'EE87925', 'EE87926', 'EE87927', 'EE87928', 'EE87929', 'EE87931', 'EE87932', 'EE87933', 'EE87934', 'EE87935', 'EE87936', 'EE87937', 'EE87938', 'EE87939', 'EE87940', 'EE87941', 'EE87942', 'EE87943', 'EE87944', 'EE87947', 'EE87948', 'EE87949', 'EE87950', 'EE87951', 'EE87952', 'EE87953', 'EE87954', 'EE87955', 'EE87956', 'EE87957', 'EE87958', 'EE87959', 'EE87960', 'EE87961', 'EE87962', 'EE87963', 'EE87964', 'EE87965', 'EE87966', 'EE87967', 'EE87968', 'EE87969', 'EE87970', 'EE87971', 'EE87972', 'EE87973', 'EE87974', 'EE87975', 'EE87976', 'EE87977', 'EE87978', 'EE87979', 'EE87980', 'EE87981', 'EE87982', 'EE87983', 'EE87984', 'EE87985', 'EE87986', 'EE87987', 'EE87988', 'EE87989', 'EE87990', 'EE87991', 'EE87992', 'EE87993', 'EE87994', 'EE87995', 'EE87996', 'EE87997', 'EE87998', 'EE87999', 'EE88000', 'EE88001', 'EE88002', 'EE88003', 'EE88004', 'EE88005', 'EE88006', 'EE88007', 'EE88008', 'EE88009', 'EE88010', 'EE88011', 'EE88012', 'EE88013', 'EE88014', 'EE88015', 'EE88016', 'EE88017', 'EE88018', 'EE88019', 'EE88020', 'EE88021', 'EE88022', 'EE88023', 'EE88024', 'EE88025', 'EE88026', 'EE88027', 'EE88028', 'EE88029', 'EE88030', 'EE88031', 'EE88032']\n"
     ]
    }
   ],
   "source": [
    "cancer_samples = [\n",
    "    # bile duct cancer\n",
    "    \"EE87789\", \"EE87790\", \"EE87791\", \"EE87792\", \"EE87793\", \"EE87794\",\n",
    "    \"EE87795\", \"EE87796\", \"EE87797\", \"EE87798\", \"EE87799\", \"EE87800\",\n",
    "    \"EE87801\", \"EE87802\", \"EE87803\", \"EE87804\", \"EE87805\", \"EE87806\",\n",
    "    \"EE87807\", \"EE87809\", \"EE87810\", \"EE88325\",\n",
    "\n",
    "    # colorectal cancer\n",
    "    # nicht in clinical table\n",
    "    \"EE85727\", \"EE85730\", \"EE85731\", \"EE85732\", \"EE85733\", \"EE85734\",\n",
    "    \"EE85737\", \"EE85739\", \"EE85741\", \"EE85743\", \"EE85746\", \"EE85749\",\n",
    "    \"EE85750\", \"EE85752\", \"EE85753\", \n",
    "    \n",
    "    \n",
    "    \n",
    "    \"EE86234\", \"EE86255\", \"EE86259\",\n",
    "    \"EE87865\", \"EE87866\", \"EE87867\", \"EE87868\", \"EE87869\", \"EE87870\",\n",
    "    \"EE87871\", \"EE87872\", \"EE87873\", \"EE87874\", \"EE87875\", \"EE87876\",\n",
    "    \"EE87877\", \"EE87878\", \"EE87879\", \"EE87880\", \"EE87881\", \"EE87882\",\n",
    "    \"EE87883\", \"EE87884\", \"EE87885\", \"EE87886\", \"EE87887\", \"EE87888\",\n",
    "    \"EE87889\", \"EE87890\", \"EE87891\",\n",
    "\n",
    "    # gastric cancer\n",
    "    \"EE87896\", \"EE87897\", \"EE87898\", \"EE87899\", \"EE87900\", \"EE87901\",\n",
    "    \"EE87902\", \"EE87903\", \"EE87904\", \"EE87905\", \"EE87906\", \"EE87907\",\n",
    "    \"EE87908\", \"EE87909\", \"EE87910\", \"EE87911\", \"EE87912\", \"EE87913\",\n",
    "    \"EE87914\", \"EE87915\", \"EE87916\", \"EE87917\", \"EE87918\", \"EE87919\",\n",
    "\n",
    "    # pancreatic cancer\n",
    "    \"EE86268\", \"EE86270\", \"EE86271\", \"EE86272\", \"EE86273\",\n",
    "    \"EE88290\", \"EE88291\", \"EE88292\", \"EE88293\", \"EE88294\", \"EE88295\",\n",
    "    \"EE88296\", \"EE88297\", \"EE88298\", \"EE88299\", \"EE88300\", \"EE88301\",\n",
    "    \"EE88302\", \"EE88303\", \"EE88304\", \"EE88305\", \"EE88306\", \"EE88307\",\n",
    "    \"EE88308\", \"EE88309\", \"EE88310\", \"EE88311\", \"EE88312\", \"EE88313\",\n",
    "    \"EE88314\", \"EE88315\", \"EE88316\", \"EE88317\", \"EE88318\", \"EE88319\",\n",
    "    \"EE88320\", \"EE88321\", \"EE88322\", \"EE88323\", \"EE88324\"\n",
    "]\n",
    "control_samples = [\n",
    "\n",
    "    # healthy controls\n",
    "    # nicht in clinical table\n",
    "    \"EE85898\", \"EE85904\", \"EE85905\", \"EE85908\", \"EE85918\", \"EE85928\",\n",
    "    \"EE85936\", \"EE85937\", \"EE85941\", \"EE85959\", \"EE85963\", \"EE85970\",\n",
    "    \"EE85971\", \"EE85980\", \"EE85985\", \"EE85987\", \"EE85988\", \"EE86275\",\n",
    "    \"EE86276\", \"EE87945\", \"EE87946\",\n",
    "    \n",
    "\n",
    "    \n",
    "    \"EE87920\", \"EE87921\", \"EE87922\", \"EE87923\", \"EE87924\",\n",
    "    \"EE87925\", \"EE87926\", \"EE87927\", \"EE87928\", \"EE87929\", \"EE87931\",\n",
    "    \"EE87932\", \"EE87933\", \"EE87934\", \"EE87935\", \"EE87936\", \"EE87937\",\n",
    "    \"EE87938\", \"EE87939\", \"EE87940\", \"EE87941\", \"EE87942\", \"EE87943\",\n",
    "    \"EE87944\", \"EE87947\", \"EE87948\", \"EE87949\",\n",
    "    \"EE87950\", \"EE87951\", \"EE87952\", \"EE87953\", \"EE87954\", \"EE87955\",\n",
    "    \"EE87956\", \"EE87957\", \"EE87958\", \"EE87959\", \"EE87960\", \"EE87961\",\n",
    "    \"EE87962\", \"EE87963\", \"EE87964\", \"EE87965\", \"EE87966\", \"EE87967\",\n",
    "    \"EE87968\", \"EE87969\", \"EE87970\", \"EE87971\", \"EE87972\", \"EE87973\",\n",
    "    \"EE87974\", \"EE87975\", \"EE87976\", \"EE87977\", \"EE87978\", \"EE87979\",\n",
    "    \"EE87980\", \"EE87981\", \"EE87982\", \"EE87983\", \"EE87984\", \"EE87985\",\n",
    "    \"EE87986\", \"EE87987\", \"EE87988\", \"EE87989\", \"EE87990\", \"EE87991\",\n",
    "    \"EE87992\", \"EE87993\", \"EE87994\", \"EE87995\", \"EE87996\", \"EE87997\",\n",
    "    \"EE87998\", \"EE87999\", \"EE88000\", \"EE88001\", \"EE88002\", \"EE88003\",\n",
    "    \"EE88004\", \"EE88005\", \"EE88006\", \"EE88007\", \"EE88008\", \"EE88009\",\n",
    "    \"EE88010\", \"EE88011\", \"EE88012\", \"EE88013\", \"EE88014\", \"EE88015\",\n",
    "    \"EE88016\", \"EE88017\", \"EE88018\", \"EE88019\", \"EE88020\", \"EE88021\",\n",
    "    \"EE88022\", \"EE88023\", \"EE88024\", \"EE88025\", \"EE88026\", \"EE88027\",\n",
    "    \"EE88028\", \"EE88029\", \"EE88030\", \"EE88031\", \"EE88032\"\n",
    "]\n",
    "\n",
    "BASE_DIR = \"/labmed/workspace/lotta/finaletoolkit/carsten/data_adjust_wps\"\n",
    "\n",
    "def find_sample_folder(sample, base_dir=BASE_DIR):\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for f in files:\n",
    "            if f.startswith(sample) and f.endswith(\".adjust_wps.bw\"):\n",
    "                return root\n",
    "    return None\n",
    "\n",
    "def get_bigwig_path(sample):\n",
    "    folder = find_sample_folder(sample)\n",
    "    if folder is None:\n",
    "        raise FileNotFoundError(f\"Sample {sample} not found in {BASE_DIR}\")\n",
    "    return os.path.join(folder, f\"{sample}.adjust_wps.bw\")\n",
    "\n",
    "def bigwig_summary(bigwig_path, chrom, start, end, n_bins=1):\n",
    "    bw = pyBigWig.open(bigwig_path)\n",
    "    bin_size = (end - start) // n_bins\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        b_start = start + i * bin_size\n",
    "        b_end = start + (i+1) * bin_size if i < n_bins - 1 else end\n",
    "        \n",
    "        vals = bw.values(chrom, b_start, b_end)\n",
    "        vals = [v for v in vals if v is not None and not math.isnan(v)]\n",
    "        \n",
    "        results.append(sum(vals)/len(vals) if vals else 0)\n",
    "\n",
    "    bw.close()\n",
    "    return results\n",
    "\n",
    "all_samples = cancer_samples + control_samples\n",
    "print(f\"Configuration loaded for {len(all_samples)} samples:\")\n",
    "print(all_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d40e0",
   "metadata": {},
   "source": [
    "# Cancer Typ aus dem Pfad extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c171e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cancer_type(sample):\n",
    "    folder = find_sample_folder(sample)  \n",
    "    if folder is None:\n",
    "        return \"Unknown\"\n",
    "    return os.path.basename(folder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918eeb7",
   "metadata": {},
   "source": [
    "# Creating and Loading of Bedgraph Files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34af20",
   "metadata": {},
   "source": [
    "# Bin-Wide-Analysis, Binning the genome, Bin Size in Config File \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0de450d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Loading existing binned dataframe from /labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/binned_combined_df_50000.parquet...\n"
     ]
    }
   ],
   "source": [
    "bedgraph_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/carsten/data_adjust_wps')\n",
    "from config import BIN_SIZE as bin_size\n",
    "print(bin_size)\n",
    "\n",
    "binned_output_path = f\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/binned_combined_df_{bin_size}.parquet\"\n",
    "\n",
    "all_binned_dfs = []\n",
    "\n",
    "if os.path.exists(binned_output_path):\n",
    "    print(f\"Loading existing binned dataframe from {binned_output_path}...\")\n",
    "    binned_combined_df = pd.read_parquet(binned_output_path)\n",
    "else:\n",
    "    print(f\"Creating new binned dataframe with bin size {bin_size}...\")\n",
    "    \n",
    "    def find_bedgraphs(sample_id):\n",
    "        # pattern ist der gesuchte Dateipfad\n",
    "        pattern = os.path.join(bedgraph_dir, \"**\", f\"{sample_id}.adjust_wps.bedgraph\")\n",
    "\n",
    "        # matches sind alle gefundenen Dateien, die dem Muster entsprechen\n",
    "        matches = glob.glob(pattern, recursive=True)\n",
    "        # Gibt die erste gefundene Datei zurÃ¼ck \n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    for sample_id in all_samples:\n",
    "        file_path = find_bedgraphs(sample_id)\n",
    "        if file_path:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\", \"wps_value\"])\n",
    "                df['sample'] = sample_id\n",
    "                group = get_cancer_type(sample_id)\n",
    "                df['group'] = group\n",
    "                \n",
    "                # IMMEDIATE BINNING TO SAVE MEMORY\n",
    "                df['bin'] = df['start'] // bin_size\n",
    "                # Calculate mean per bin for this sample immediately\n",
    "                df_binned = df.groupby(['sample', 'group', 'chrom', 'bin'])['wps_value'].mean().reset_index()\n",
    "                \n",
    "                all_binned_dfs.append(df_binned)\n",
    "                print(f\"Loaded and binned {sample_id}. Rows: {len(df)} -> {len(df_binned)}\")\n",
    "                \n",
    "                del df\n",
    "                gc.collect()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"Bedgraph file for sample {sample_id} not found.\")\n",
    "\n",
    "    if all_binned_dfs:\n",
    "        binned_combined_df = pd.concat(all_binned_dfs, ignore_index=True)\n",
    "        print(f\"Data successfully loaded and binned. Total rows: {len(binned_combined_df)}\")\n",
    "        \n",
    "        # Apply median imputation for (chrom, bin) groups\n",
    "               # Check for NaN values before imputation\n",
    "        nan_count = binned_combined_df['wps_value'].isna().sum()\n",
    "        print(f\"Number of NaN values before imputation: {nan_count}\")\n",
    "\n",
    "        if nan_count > 0:\n",
    "            print(\"Applying median imputation...\")\n",
    "            binned_combined_df['wps_value'] = binned_combined_df.groupby(['chrom', 'bin'])['wps_value'].transform(lambda x: x.fillna(x.median()))\n",
    "        else:\n",
    "            print(\"No NaN values found. Skipping imputation.\")\n",
    "        binned_combined_df.to_parquet(binned_output_path)\n",
    "        print(f\"Saved binned dataframe to {binned_output_path}\")\n",
    "    else:\n",
    "        print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a9f42",
   "metadata": {},
   "source": [
    "# Feature Matrix for LR rows=sample and columns=bins+groups \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b799e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing final feature matrix...\n"
     ]
    }
   ],
   "source": [
    "binned_combined_df = pd.read_parquet(\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/binned_combined_df_50000.parquet\")\n",
    "if os.path.exists(f\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/final_feature_matrix_{bin_size}.parquet\"):\n",
    "    print(\"Loading existing final feature matrix...\")\n",
    "    final_feature_matrix = pd.read_parquet(f\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/final_feature_matrix_{bin_size}.parquet\")\n",
    "else:\n",
    "    binned_combined_df['feature_name'] = binned_combined_df['chrom'] + '_bin_' + binned_combined_df['bin'].astype(str)\n",
    "    feature_matrix = binned_combined_df.pivot(index='sample', columns='feature_name', values='wps_value')\n",
    "    group_info = binned_combined_df[['sample', 'group']].drop_duplicates().set_index('sample')\n",
    "    final_feature_matrix = feature_matrix.join(group_info)\n",
    "    final_feature_matrix = final_feature_matrix.fillna(0)\n",
    "    final_feature_matrix.to_parquet(f\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/final_feature_matrix_{bin_size}.parquet\", index=True)\n",
    "    print(final_feature_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab92a44",
   "metadata": {},
   "source": [
    "# Fragment Interval Analysis: Loading Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_interval_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/output_workflow/frag_intervals')\n",
    "frag_intervals_results = []\n",
    "for sample in all_samples:\n",
    "    interval_path = os.path.join(frag_interval_dir, '**', f\"{sample}.frag_length_intervals.bed\")\n",
    "    files = glob.glob(interval_path, recursive=True)\n",
    "    if not files:\n",
    "        print(f\"Fragment length Interval file for sample {sample} not found.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(\n",
    "    files[0],\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"chrom\", \"start\", \"stop\", \"name\", \"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    )\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    group = get_cancer_type(sample)\n",
    "    df['sample'] = sample\n",
    "    df['group'] = group\n",
    "    df[\"start\"] = df[\"start\"].astype(int)\n",
    "    df[\"stop\"] = df[\"stop\"].astype(int)\n",
    "\n",
    "    num_cols = [\"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    df[num_cols] = df[num_cols].astype(float)\n",
    "    df['bin'] = df['start'] // bin_size\n",
    "    frag_intervals_results.append(df)\n",
    "\n",
    "frag_intervals_df = pd.concat(frag_intervals_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13515a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom    start     stop name        mean  median      stdev    min    max  \\\n",
      "0  chr1   920000   925000    .  159.137255   161.0  16.761323  120.0  190.0   \n",
      "1  chr1  1070000  1075000    .  167.342857   165.0  16.101363  138.0  208.0   \n",
      "2  chr1  1165000  1170000    .  166.767442   165.0  21.334367  113.0  233.0   \n",
      "3  chr1  1170000  1175000    .  162.823529   165.5  21.494829  108.0  201.0   \n",
      "4  chr1  1175000  1180000    .  170.400000   170.0  18.626862  121.0  218.0   \n",
      "\n",
      "    sample     group  bin  \n",
      "0  EE87789  bileduct   18  \n",
      "1  EE87789  bileduct   21  \n",
      "2  EE87789  bileduct   23  \n",
      "3  EE87789  bileduct   23  \n",
      "4  EE87789  bileduct   23  \n"
     ]
    }
   ],
   "source": [
    "print(frag_intervals_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecf730",
   "metadata": {},
   "source": [
    "# Binning Fragment Interval Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a40f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean      median      stdev  \\\n",
      "0  EE85727  colorectal  chr1   18   85.500000   85.500000  63.500000   \n",
      "1  EE85727  colorectal  chr1   21  133.500000  133.500000   0.500000   \n",
      "2  EE85727  colorectal  chr1   23   84.873016   86.000000  15.918508   \n",
      "3  EE85727  colorectal  chr1   25  127.125000   99.000000  57.685560   \n",
      "4  EE85727  colorectal  chr1   26  114.433333  105.833333  23.568542   \n",
      "\n",
      "          min         max  \n",
      "0   22.000000  149.000000  \n",
      "1  133.000000  134.000000  \n",
      "2   49.000000  103.666667  \n",
      "3   63.500000  218.500000  \n",
      "4   80.666667  140.333333  \n",
      "(1122670, 9)\n"
     ]
    }
   ],
   "source": [
    "binned_df = (\n",
    "    frag_intervals_df.groupby(['sample', 'group', 'chrom', 'bin'])\n",
    "      .agg({\n",
    "          \"mean\": \"mean\",\n",
    "          \"median\": \"mean\",\n",
    "          \"stdev\": \"mean\",\n",
    "          \"min\": \"mean\",\n",
    "          \"max\": \"mean\"\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(binned_df.head())\n",
    "print(binned_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b20d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample     group chrom  bin  wps_value feature_name\n",
      "0  EE87789  bileduct  chr1   18   0.051597  chr1_bin_18\n",
      "1  EE87789  bileduct  chr1   21  -0.174507  chr1_bin_21\n",
      "2  EE87789  bileduct  chr1   23  -0.274645  chr1_bin_23\n",
      "3  EE87789  bileduct  chr1   25  -0.105827  chr1_bin_25\n",
      "4  EE87789  bileduct  chr1   26  -0.339625  chr1_bin_26\n"
     ]
    }
   ],
   "source": [
    "print(binned_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd2e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean      median      stdev  \\\n",
      "0  EE85727  colorectal  chr1   18   85.500000   85.500000  63.500000   \n",
      "1  EE85727  colorectal  chr1   21  133.500000  133.500000   0.500000   \n",
      "2  EE85727  colorectal  chr1   23   84.873016   86.000000  15.918508   \n",
      "3  EE85727  colorectal  chr1   25  127.125000   99.000000  57.685560   \n",
      "4  EE85727  colorectal  chr1   26  114.433333  105.833333  23.568542   \n",
      "\n",
      "          min         max  wps_value  \n",
      "0   22.000000  149.000000    -0.0422  \n",
      "1  133.000000  134.000000    -0.0906  \n",
      "2   49.000000  103.666667    -0.2056  \n",
      "3   63.500000  218.500000    -0.0867  \n",
      "4   80.666667  140.333333    -0.0538  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(\n",
    "    binned_df,\n",
    "    binned_combined_df[['sample', 'chrom', 'bin', 'wps_value']],\n",
    "    how='left',\n",
    "    on=['sample', 'chrom', 'bin']\n",
    ")\n",
    "\n",
    "print(merged_df.head())\n",
    "merged_df.to_csv(f\"/labmed/workspace/lotta/finaletoolkit/dataframes_for_ba/final_feature_matrix_{bin_size}.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fragmentomics_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
