{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59dada",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b43aa881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, levene, ranksums\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import math\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import importlib\n",
    "import config \n",
    "importlib.reload(config)\n",
    "from config import BIN_SIZE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499beba",
   "metadata": {},
   "source": [
    "# Loading Samples (30 Holdout-Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d749d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for 30 samples:\n",
      "['EE87786', 'EE87787', 'EE87788', 'EE85723', 'EE85724', 'EE85726', 'EE87892', 'EE86253', 'EE86266', 'EE87893', 'EE87894', 'EE87895', 'EE86244', 'EE86247', 'EE86248', 'EE85756', 'EE85757', 'EE85770', 'EE85775', 'EE85784', 'EE85787', 'EE85791', 'EE85795', 'EE85816', 'EE85830', 'EE85842', 'EE85854', 'EE85860', 'EE85861', 'EE85878']\n"
     ]
    }
   ],
   "source": [
    "cancer_samples = [\n",
    "    # bile duct cancer\n",
    "    \"EE87786\", \"EE87787\", \"EE87788\",\n",
    "\n",
    "    # colorectal \n",
    "    \"EE85723\", \"EE85724\", \"EE85726\",\n",
    "\n",
    "    #duodenal\n",
    "    \"EE87892\",\n",
    "\n",
    "    #eso\n",
    "    \"EE86253\", \"EE86266\",\n",
    "\n",
    "    #gastric\n",
    "    \"EE87893\", \"EE87894\", \"EE87895\",\n",
    "\n",
    "    #pancreatic\n",
    "    \"EE86244\", \"EE86247\", \"EE86248\",\n",
    "\n",
    "]\n",
    "control_samples = [\n",
    "    \"EE85756\",\n",
    "    \"EE85757\",\n",
    "    \"EE85770\",\n",
    "    \"EE85775\",\n",
    "    \"EE85784\",\n",
    "    \"EE85787\",\n",
    "\"EE85791\",\n",
    "\"EE85795\",\n",
    "\"EE85816\",\n",
    "\"EE85830\",\n",
    "\"EE85842\",\n",
    "\"EE85854\",\n",
    "\"EE85860\",\n",
    "\"EE85861\",\n",
    "\"EE85878\",\n",
    "\n",
    "]\n",
    "\n",
    "BASE_DIR = \"/labmed/workspace/lotta/finaletoolkit/carsten/outputs_holdout\"\n",
    "\n",
    "def find_sample_folder(sample, base_dir=BASE_DIR):\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for f in files:\n",
    "            if f.startswith(sample) and f.endswith(\".adjust_wps.bw\"):\n",
    "                return root\n",
    "    return None\n",
    "\n",
    "def get_bigwig_path(sample):\n",
    "    folder = find_sample_folder(sample)\n",
    "    if folder is None:\n",
    "        raise FileNotFoundError(f\"Sample {sample} not found in {BASE_DIR}\")\n",
    "    return os.path.join(folder, f\"{sample}.adjust_wps.bw\")\n",
    "\n",
    "def bigwig_summary(bigwig_path, chrom, start, end, n_bins=1):\n",
    "    bw = pyBigWig.open(bigwig_path)\n",
    "    bin_size = (end - start) // n_bins\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        b_start = start + i * bin_size\n",
    "        b_end = start + (i+1) * bin_size if i < n_bins - 1 else end\n",
    "        \n",
    "        vals = bw.values(chrom, b_start, b_end)\n",
    "        vals = [v for v in vals if v is not None and not math.isnan(v)]\n",
    "        \n",
    "        results.append(sum(vals)/len(vals) if vals else 0)\n",
    "\n",
    "    bw.close()\n",
    "    return results\n",
    "\n",
    "all_samples = cancer_samples + control_samples\n",
    "print(f\"Configuration loaded for {len(all_samples)} samples:\")\n",
    "print(all_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d40e0",
   "metadata": {},
   "source": [
    "# Cancer Typ aus dem Pfad extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c171e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cancer_type(sample):\n",
    "    folder = find_sample_folder(sample)  \n",
    "    if folder is None:\n",
    "        return \"Unknown\"\n",
    "    return os.path.basename(folder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918eeb7",
   "metadata": {},
   "source": [
    "# Creating and Loading of Bedgraph Files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34af20",
   "metadata": {},
   "source": [
    "# Bin-Wide-Analysis, Binning the genome, Bin Size in Config File \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de450d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Creating new binned dataframe with bin size 10000...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded and binned EE87786. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87787. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87788. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85723. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85724. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85726. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87892. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE86253. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE86266. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87893. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87894. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE87895. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE86244. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE86247. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE86248. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85756. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85757. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85770. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85775. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85784. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85787. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85791. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85795. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85816. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85830. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85842. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85854. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85860. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85861. Rows: 26110000 -> 4936\n",
      "Loaded and binned EE85878. Rows: 26110000 -> 4936\n",
      "Data successfully loaded and binned. Total rows: 148080\n",
      "Number of NaN values before imputation: 0\n",
      "No NaN values found. Skipping imputation.\n",
      "Saved binned dataframe to /labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_10000.parquet\n"
     ]
    }
   ],
   "source": [
    "bedgraph_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/carsten/outputs_holdout/')\n",
    "from config import BIN_SIZE\n",
    "print(BIN_SIZE)\n",
    "\n",
    "binned_output_path = f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_{BIN_SIZE}.parquet\"\n",
    "\n",
    "all_binned_dfs = []\n",
    "\n",
    "if os.path.exists(binned_output_path):\n",
    "    print(f\"Loading existing binned dataframe from {binned_output_path}...\")\n",
    "    binned_combined_df = pd.read_parquet(binned_output_path)\n",
    "else:\n",
    "    print(f\"Creating new binned dataframe with bin size {BIN_SIZE}...\")\n",
    "    \n",
    "    def find_bedgraphs(sample_id):\n",
    "        # pattern ist der gesuchte Dateipfad\n",
    "        pattern = os.path.join(bedgraph_dir, \"**\", f\"{sample_id}.adjust_wps.bedgraph\")\n",
    "\n",
    "        # matches sind alle gefundenen Dateien, die dem Muster entsprechen\n",
    "        matches = glob.glob(pattern, recursive=True)\n",
    "        # Gibt die erste gefundene Datei zurÃ¼ck \n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    for sample_id in all_samples:\n",
    "        file_path = find_bedgraphs(sample_id)\n",
    "        if file_path:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\", \"wps_value\"])\n",
    "                df['sample'] = sample_id\n",
    "                group = get_cancer_type(sample_id)\n",
    "                df['group'] = group\n",
    "                \n",
    "                # IMMEDIATE BINNING TO SAVE MEMORY\n",
    "                df['bin'] = df['start'] // BIN_SIZE\n",
    "                # Calculate mean per bin for this sample immediately\n",
    "                df_binned = df.groupby(['sample', 'group', 'chrom', 'bin'])['wps_value'].mean().reset_index()\n",
    "                \n",
    "                all_binned_dfs.append(df_binned)\n",
    "                print(f\"Loaded and binned {sample_id}. Rows: {len(df)} -> {len(df_binned)}\")\n",
    "                \n",
    "                del df\n",
    "                gc.collect()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"Bedgraph file for sample {sample_id} not found.\")\n",
    "\n",
    "    if all_binned_dfs:\n",
    "        binned_combined_df = pd.concat(all_binned_dfs, ignore_index=True)\n",
    "        print(f\"Data successfully loaded and binned. Total rows: {len(binned_combined_df)}\")\n",
    "        \n",
    "        # Apply median imputation for (chrom, bin) groups\n",
    "               # Check for NaN values before imputation\n",
    "        nan_count = binned_combined_df['wps_value'].isna().sum()\n",
    "        print(f\"Number of NaN values before imputation: {nan_count}\")\n",
    "\n",
    "        if nan_count > 0:\n",
    "            print(\"Applying median imputation...\")\n",
    "            binned_combined_df['wps_value'] = binned_combined_df.groupby(['chrom', 'bin'])['wps_value'].transform(lambda x: x.fillna(x.median()))\n",
    "        else:\n",
    "            print(\"No NaN values found. Skipping imputation.\")\n",
    "        binned_combined_df.to_parquet(binned_output_path)\n",
    "        print(f\"Saved binned dataframe to {binned_output_path}\")\n",
    "    else:\n",
    "        print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a9f42",
   "metadata": {},
   "source": [
    "# Feature Matrix for LR rows=sample and columns=bins+groups \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b799e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         chr10_bin_10097  chr10_bin_10098  chr10_bin_10099  chr10_bin_10106  \\\n",
      "sample                                                                        \n",
      "EE85723        -0.116600        -0.453800        -0.177600        -0.066690   \n",
      "EE85724        -0.136400        -0.516800        -0.124800        -0.276400   \n",
      "EE85726        -0.441400        -0.326200        -0.161497        -0.332259   \n",
      "EE85756        -0.334571        -0.117978        -0.075252        -0.093200   \n",
      "EE85757        -0.168822        -0.253815         0.064400        -0.367172   \n",
      "\n",
      "         chr10_bin_10140  chr10_bin_10158  chr10_bin_10177  chr10_bin_10178  \\\n",
      "sample                                                                        \n",
      "EE85723        -0.292400        -0.464600        -0.046600        -0.206200   \n",
      "EE85724        -0.675135        -0.810837        -0.215200        -0.494600   \n",
      "EE85726        -0.538400        -0.476800        -0.083800        -0.349000   \n",
      "EE85756        -0.081948         0.175499        -0.504200        -0.401066   \n",
      "EE85757        -0.192433        -0.202319        -0.123568        -0.085000   \n",
      "\n",
      "         chr10_bin_10181  chr10_bin_10184  ...  chr9_bin_9722  chr9_bin_9730  \\\n",
      "sample                                     ...                                 \n",
      "EE85723        -0.606526        -0.238200  ...      -1.250400      -0.693400   \n",
      "EE85724        -0.198700        -0.198600  ...      -0.839400      -0.473200   \n",
      "EE85726        -0.735626        -0.343200  ...      -0.947526      -0.802185   \n",
      "EE85756        -0.060984        -0.246239  ...      -0.068448       0.215742   \n",
      "EE85757        -0.547526        -0.022606  ...      -0.489313      -0.517763   \n",
      "\n",
      "         chr9_bin_9741  chr9_bin_9798  chr9_bin_9805  chr9_bin_9887  \\\n",
      "sample                                                                \n",
      "EE85723      -0.855811      -0.571000      -0.109022      -0.373600   \n",
      "EE85724      -1.614400      -1.090600      -0.055400      -0.986611   \n",
      "EE85726      -0.830520      -1.253200      -0.319178      -1.053400   \n",
      "EE85756       0.065042      -0.374411      -0.592434      -0.444800   \n",
      "EE85757       0.094550      -0.026015      -0.214788       0.273614   \n",
      "\n",
      "         chr9_bin_9922  chr9_bin_9945  chr9_bin_9982       group  \n",
      "sample                                                            \n",
      "EE85723      -1.017400      -0.898813      -0.130600  colorectal  \n",
      "EE85724      -1.463000      -0.099069      -0.047200  colorectal  \n",
      "EE85726      -1.301243      -1.086478      -0.217200  colorectal  \n",
      "EE85756      -0.430189      -0.216534      -0.015800     healthy  \n",
      "EE85757      -0.023806      -0.338905      -0.268176     healthy  \n",
      "\n",
      "[5 rows x 4937 columns]\n"
     ]
    }
   ],
   "source": [
    "binned_combined_df = pd.read_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_{BIN_SIZE}.parquet\")\n",
    "if os.path.exists(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\"):\n",
    "    print(\"Loading existing final feature matrix...\")\n",
    "    final_feature_matrix = pd.read_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\")\n",
    "else:\n",
    "    binned_combined_df['feature_name'] = binned_combined_df['chrom'] + '_bin_' + binned_combined_df['bin'].astype(str)\n",
    "    feature_matrix = binned_combined_df.pivot(index='sample', columns='feature_name', values='wps_value')\n",
    "    group_info = binned_combined_df[['sample', 'group']].drop_duplicates().set_index('sample')\n",
    "    final_feature_matrix = feature_matrix.join(group_info)\n",
    "    final_feature_matrix = final_feature_matrix.fillna(0)\n",
    "    final_feature_matrix.to_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\", index=True)\n",
    "    print(final_feature_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab92a44",
   "metadata": {},
   "source": [
    "# Fragment Interval Analysis: Loading Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "656ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_interval_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/frag_intervals')\n",
    "frag_intervals_results = []\n",
    "for sample in all_samples:\n",
    "    interval_path = os.path.join(frag_interval_dir, '**', f\"{sample}.frag_length_intervals.bed\")\n",
    "    files = glob.glob(interval_path, recursive=True)\n",
    "    if not files:\n",
    "        print(f\"Fragment length Interval file for sample {sample} not found.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(\n",
    "    files[0],\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"chrom\", \"start\", \"stop\", \"name\", \"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    )\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    group = get_cancer_type(sample)\n",
    "    df['sample'] = sample\n",
    "    df['group'] = group\n",
    "    df[\"start\"] = df[\"start\"].astype(int)\n",
    "    df[\"stop\"] = df[\"stop\"].astype(int)\n",
    "\n",
    "    num_cols = [\"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    df[num_cols] = df[num_cols].astype(float)\n",
    "    df['bin'] = df['start'] // BIN_SIZE\n",
    "    frag_intervals_results.append(df)\n",
    "\n",
    "frag_intervals_df = pd.concat(frag_intervals_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13515a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom    start     stop name        mean  median      stdev    min    max  \\\n",
      "0  chr1   920000   925000    .  166.857143   166.5  19.576433  101.0  224.0   \n",
      "1  chr1  1070000  1075000    .  167.150000   168.5  15.642970  122.0  202.0   \n",
      "2  chr1  1165000  1170000    .  165.625000   163.5  14.876350  131.0  209.0   \n",
      "3  chr1  1170000  1175000    .  168.523077   166.0  14.124836  141.0  217.0   \n",
      "4  chr1  1175000  1180000    .  167.645161   167.5  15.520119  124.0  204.0   \n",
      "\n",
      "    sample     group  bin  \n",
      "0  EE87786  bileduct   92  \n",
      "1  EE87786  bileduct  107  \n",
      "2  EE87786  bileduct  116  \n",
      "3  EE87786  bileduct  117  \n",
      "4  EE87786  bileduct  117  \n"
     ]
    }
   ],
   "source": [
    "print(frag_intervals_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecf730",
   "metadata": {},
   "source": [
    "# Binning Fragment Interval Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a40f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean  median      stdev    min    max\n",
      "0  EE85723  colorectal  chr1   92  109.333333    64.0  32.887012   64.0  141.0\n",
      "1  EE85723  colorectal  chr1  107  111.000000   111.0   0.000000  111.0  111.0\n",
      "2  EE85723  colorectal  chr1  116   -1.000000    -1.0  -1.000000   -1.0   -1.0\n",
      "3  EE85723  colorectal  chr1  117  144.875000   151.0  32.084303   86.5  184.0\n",
      "4  EE85723  colorectal  chr1  126  117.500000   117.5  12.500000  105.0  130.0\n",
      "(148080, 9)\n"
     ]
    }
   ],
   "source": [
    "binned_df = (\n",
    "    frag_intervals_df.groupby(['sample', 'group', 'chrom', 'bin'])\n",
    "      .agg({\n",
    "          \"mean\": \"mean\",\n",
    "          \"median\": \"mean\",\n",
    "          \"stdev\": \"mean\",\n",
    "          \"min\": \"mean\",\n",
    "          \"max\": \"mean\"\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(binned_df.head())\n",
    "print(binned_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14e2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.008414370610480821)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(binned_df[[\"mean\",\"median\",\"stdev\",\"min\",\"max\"]] == -1).sum()\n",
    "(binned_df[\"mean\"] == -1).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b20d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample     group chrom  bin  wps_value  feature_name\n",
      "0  EE87786  bileduct  chr1   92  -0.165352   chr1_bin_92\n",
      "1  EE87786  bileduct  chr1  107  -0.520809  chr1_bin_107\n",
      "2  EE87786  bileduct  chr1  116   0.060852  chr1_bin_116\n",
      "3  EE87786  bileduct  chr1  117  -0.093078  chr1_bin_117\n",
      "4  EE87786  bileduct  chr1  126   0.007216  chr1_bin_126\n"
     ]
    }
   ],
   "source": [
    "print(binned_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbd2e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean  median      stdev    min  \\\n",
      "0  EE85723  colorectal  chr1   92  109.333333    64.0  32.887012   64.0   \n",
      "1  EE85723  colorectal  chr1  107  111.000000   111.0   0.000000  111.0   \n",
      "2  EE85723  colorectal  chr1  116   -1.000000    -1.0  -1.000000   -1.0   \n",
      "3  EE85723  colorectal  chr1  117  144.875000   151.0  32.084303   86.5   \n",
      "4  EE85723  colorectal  chr1  126  117.500000   117.5  12.500000  105.0   \n",
      "\n",
      "     max  wps_value  \n",
      "0  141.0  -0.091200  \n",
      "1  111.0   0.000000  \n",
      "2   -1.0   0.000000  \n",
      "3  184.0  -0.193100  \n",
      "4  130.0  -0.045973  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(\n",
    "    binned_df,\n",
    "    binned_combined_df[['sample', 'chrom', 'bin', 'wps_value']],\n",
    "    how='left',\n",
    "    on=['sample', 'chrom', 'bin']\n",
    ")\n",
    "\n",
    "print(merged_df.head())\n",
    "merged_df.to_csv(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
