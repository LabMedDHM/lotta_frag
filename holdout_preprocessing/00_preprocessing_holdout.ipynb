{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a59dada",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b43aa881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind, levene, ranksums\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pyBigWig\n",
    "import math\n",
    "import re\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.multivariate.manova import MANOVA\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import importlib\n",
    "import config \n",
    "importlib.reload(config)\n",
    "from config import BIN_SIZE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b499beba",
   "metadata": {},
   "source": [
    "# Loading Samples (30 Holdout-Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d749d3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for 30 samples:\n",
      "['EE87786', 'EE87787', 'EE87788', 'EE85723', 'EE85724', 'EE85726', 'EE87892', 'EE86253', 'EE86266', 'EE87893', 'EE87894', 'EE87895', 'EE86244', 'EE86247', 'EE86248', 'EE85756', 'EE85757', 'EE85770', 'EE85775', 'EE85784', 'EE85787', 'EE85791', 'EE85795', 'EE85816', 'EE85830', 'EE85842', 'EE85854', 'EE85860', 'EE85861', 'EE85878']\n"
     ]
    }
   ],
   "source": [
    "cancer_samples = [\n",
    "    # bile duct cancer\n",
    "    \"EE87786\", \"EE87787\", \"EE87788\",\n",
    "\n",
    "    # colorectal \n",
    "    \"EE85723\", \"EE85724\", \"EE85726\",\n",
    "\n",
    "    #duodenal\n",
    "    \"EE87892\",\n",
    "\n",
    "    #eso\n",
    "    \"EE86253\", \"EE86266\",\n",
    "\n",
    "    #gastric\n",
    "    \"EE87893\", \"EE87894\", \"EE87895\",\n",
    "\n",
    "    #pancreatic\n",
    "    \"EE86244\", \"EE86247\", \"EE86248\",\n",
    "\n",
    "]\n",
    "control_samples = [\n",
    "    \"EE85756\",\n",
    "    \"EE85757\",\n",
    "    \"EE85770\",\n",
    "    \"EE85775\",\n",
    "    \"EE85784\",\n",
    "    \"EE85787\",\n",
    "\"EE85791\",\n",
    "\"EE85795\",\n",
    "\"EE85816\",\n",
    "\"EE85830\",\n",
    "\"EE85842\",\n",
    "\"EE85854\",\n",
    "\"EE85860\",\n",
    "\"EE85861\",\n",
    "\"EE85878\",\n",
    "\n",
    "]\n",
    "\n",
    "BASE_DIR = \"/labmed/workspace/lotta/finaletoolkit/carsten/outputs_holdout\"\n",
    "\n",
    "def find_sample_folder(sample, base_dir=BASE_DIR):\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for f in files:\n",
    "            if f.startswith(sample) and f.endswith(\".adjust_wps.bw\"):\n",
    "                return root\n",
    "    return None\n",
    "\n",
    "def get_bigwig_path(sample):\n",
    "    folder = find_sample_folder(sample)\n",
    "    if folder is None:\n",
    "        raise FileNotFoundError(f\"Sample {sample} not found in {BASE_DIR}\")\n",
    "    return os.path.join(folder, f\"{sample}.adjust_wps.bw\")\n",
    "\n",
    "def bigwig_summary(bigwig_path, chrom, start, end, n_bins=1):\n",
    "    bw = pyBigWig.open(bigwig_path)\n",
    "    bin_size = (end - start) // n_bins\n",
    "    results = []\n",
    "    \n",
    "    for i in range(n_bins):\n",
    "        b_start = start + i * bin_size\n",
    "        b_end = start + (i+1) * bin_size if i < n_bins - 1 else end\n",
    "        \n",
    "        vals = bw.values(chrom, b_start, b_end)\n",
    "        vals = [v for v in vals if v is not None and not math.isnan(v)]\n",
    "        \n",
    "        results.append(sum(vals)/len(vals) if vals else 0)\n",
    "\n",
    "    bw.close()\n",
    "    return results\n",
    "\n",
    "all_samples = cancer_samples + control_samples\n",
    "print(f\"Configuration loaded for {len(all_samples)} samples:\")\n",
    "print(all_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d40e0",
   "metadata": {},
   "source": [
    "# Cancer Typ aus dem Pfad extrahieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c171e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cancer_type(sample):\n",
    "    folder = find_sample_folder(sample)  \n",
    "    if folder is None:\n",
    "        return \"Unknown\"\n",
    "    return os.path.basename(folder) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7918eeb7",
   "metadata": {},
   "source": [
    "# Creating and Loading of Bedgraph Files "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf34af20",
   "metadata": {},
   "source": [
    "# Bin-Wide-Analysis, Binning the genome, Bin Size in Config File \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de450d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "Creating new binned dataframe with bin size 50000...\n",
      "Loaded and binned EE87786. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87787. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87788. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85723. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85724. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85726. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87892. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE86253. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE86266. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87893. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87894. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE87895. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE86244. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE86247. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE86248. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85756. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85757. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85770. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85775. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85784. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85787. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85791. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85795. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85816. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85830. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85842. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85854. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85860. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85861. Rows: 26110000 -> 4285\n",
      "Loaded and binned EE85878. Rows: 26110000 -> 4285\n",
      "Data successfully loaded and binned. Total rows: 128550\n",
      "Number of NaN values before imputation: 0\n",
      "No NaN values found. Skipping imputation.\n",
      "Saved binned dataframe to /labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_50000.parquet\n"
     ]
    }
   ],
   "source": [
    "bedgraph_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/carsten/outputs_holdout/')\n",
    "from config import BIN_SIZE\n",
    "print(BIN_SIZE)\n",
    "\n",
    "binned_output_path = f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_{BIN_SIZE}.parquet\"\n",
    "\n",
    "all_binned_dfs = []\n",
    "\n",
    "if os.path.exists(binned_output_path):\n",
    "    print(f\"Loading existing binned dataframe from {binned_output_path}...\")\n",
    "    binned_combined_df = pd.read_parquet(binned_output_path)\n",
    "else:\n",
    "    print(f\"Creating new binned dataframe with bin size {BIN_SIZE}...\")\n",
    "    \n",
    "    def find_bedgraphs(sample_id):\n",
    "        # pattern ist der gesuchte Dateipfad\n",
    "        pattern = os.path.join(bedgraph_dir, \"**\", f\"{sample_id}.adjust_wps.bedgraph\")\n",
    "\n",
    "        # matches sind alle gefundenen Dateien, die dem Muster entsprechen\n",
    "        matches = glob.glob(pattern, recursive=True)\n",
    "        # Gibt die erste gefundene Datei zurÃ¼ck \n",
    "        return matches[0] if matches else None\n",
    "\n",
    "    for sample_id in all_samples:\n",
    "        file_path = find_bedgraphs(sample_id)\n",
    "        if file_path:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=\"\\t\", header=None, names=[\"chrom\", \"start\", \"end\", \"wps_value\"])\n",
    "                df['sample'] = sample_id\n",
    "                group = get_cancer_type(sample_id)\n",
    "                df['group'] = group\n",
    "                \n",
    "                # IMMEDIATE BINNING TO SAVE MEMORY\n",
    "                df['bin'] = df['start'] // BIN_SIZE\n",
    "                # Calculate mean per bin for this sample immediately\n",
    "                df_binned = df.groupby(['sample', 'group', 'chrom', 'bin'])['wps_value'].mean().reset_index()\n",
    "                \n",
    "                all_binned_dfs.append(df_binned)\n",
    "                print(f\"Loaded and binned {sample_id}. Rows: {len(df)} -> {len(df_binned)}\")\n",
    "                \n",
    "                del df\n",
    "                gc.collect()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {sample_id}: {e}\")\n",
    "        else:\n",
    "            print(f\"Bedgraph file for sample {sample_id} not found.\")\n",
    "\n",
    "    if all_binned_dfs:\n",
    "        binned_combined_df = pd.concat(all_binned_dfs, ignore_index=True)\n",
    "        print(f\"Data successfully loaded and binned. Total rows: {len(binned_combined_df)}\")\n",
    "        \n",
    "        # Apply median imputation for (chrom, bin) groups\n",
    "               # Check for NaN values before imputation\n",
    "        nan_count = binned_combined_df['wps_value'].isna().sum()\n",
    "        print(f\"Number of NaN values before imputation: {nan_count}\")\n",
    "\n",
    "        if nan_count > 0:\n",
    "            print(\"Applying median imputation...\")\n",
    "            binned_combined_df['wps_value'] = binned_combined_df.groupby(['chrom', 'bin'])['wps_value'].transform(lambda x: x.fillna(x.median()))\n",
    "        else:\n",
    "            print(\"No NaN values found. Skipping imputation.\")\n",
    "        binned_combined_df.to_parquet(binned_output_path)\n",
    "        print(f\"Saved binned dataframe to {binned_output_path}\")\n",
    "    else:\n",
    "        print(\"No data found!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a9f42",
   "metadata": {},
   "source": [
    "# Feature Matrix for LR rows=sample and columns=bins+groups \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b799e81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         chr10_bin_1008  chr10_bin_101  chr10_bin_1055  chr10_bin_117  \\\n",
      "sample                                                                  \n",
      "EE85723       -0.670000      -0.656800       -0.336600      -0.489800   \n",
      "EE85724       -0.457054      -0.587671       -0.205400      -0.570200   \n",
      "EE85726       -0.726994      -0.792883       -0.532600      -0.541400   \n",
      "EE85756       -0.349696      -0.356106       -0.297800      -0.619643   \n",
      "EE85757       -0.307600      -0.029305        0.148367      -0.223800   \n",
      "\n",
      "         chr10_bin_1170  chr10_bin_118  chr10_bin_1186  chr10_bin_1187  \\\n",
      "sample                                                                   \n",
      "EE85723       -0.286178      -0.941986       -0.500176       -0.886115   \n",
      "EE85724       -1.572851      -0.954818       -0.131265       -1.073255   \n",
      "EE85726       -1.269734      -1.000476       -1.593978       -0.221978   \n",
      "EE85756       -0.402643       0.171563       -0.220282       -0.200454   \n",
      "EE85757        0.252263      -0.436200       -0.672245       -0.272031   \n",
      "\n",
      "         chr10_bin_1194  chr10_bin_122  ...  chr9_bin_718  chr9_bin_725  \\\n",
      "sample                                  ...                               \n",
      "EE85723       -0.872400      -0.165800  ...     -0.167400     -0.305800   \n",
      "EE85724       -0.221186      -0.432400  ...     -0.252600     -0.516600   \n",
      "EE85726       -1.779400      -0.119000  ...     -0.287200     -0.684237   \n",
      "EE85756       -0.405926      -0.246097  ...      0.005324     -0.385434   \n",
      "EE85757       -0.560960      -0.120400  ...     -0.572944     -0.233360   \n",
      "\n",
      "         chr9_bin_727  chr9_bin_729  chr9_bin_748  chr9_bin_83  chr9_bin_9  \\\n",
      "sample                                                                       \n",
      "EE85723     -1.056040     -0.441600     -0.239500    -0.365400   -1.013096   \n",
      "EE85724     -0.070868     -0.344600     -0.350900    -0.383060   -0.778176   \n",
      "EE85726     -0.560029     -0.833800     -0.340026    -1.121947   -0.585243   \n",
      "EE85756      0.044821     -0.323588     -0.069033    -0.349102    0.023240   \n",
      "EE85757     -0.132609      0.083919     -0.176469    -0.223504   -0.257493   \n",
      "\n",
      "         chr9_bin_92  chr9_bin_93       group  \n",
      "sample                                         \n",
      "EE85723    -0.301000    -0.456200  colorectal  \n",
      "EE85724    -0.749742    -0.604800  colorectal  \n",
      "EE85726    -0.615532    -0.899400  colorectal  \n",
      "EE85756     0.117281     0.104453     healthy  \n",
      "EE85757    -0.131200    -0.403696     healthy  \n",
      "\n",
      "[5 rows x 4286 columns]\n"
     ]
    }
   ],
   "source": [
    "binned_combined_df = pd.read_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/binned_combined_df_{BIN_SIZE}.parquet\")\n",
    "if os.path.exists(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\"):\n",
    "    print(\"Loading existing final feature matrix...\")\n",
    "    final_feature_matrix = pd.read_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\")\n",
    "else:\n",
    "    binned_combined_df['feature_name'] = binned_combined_df['chrom'] + '_bin_' + binned_combined_df['bin'].astype(str)\n",
    "    feature_matrix = binned_combined_df.pivot(index='sample', columns='feature_name', values='wps_value')\n",
    "    group_info = binned_combined_df[['sample', 'group']].drop_duplicates().set_index('sample')\n",
    "    final_feature_matrix = feature_matrix.join(group_info)\n",
    "    final_feature_matrix = final_feature_matrix.fillna(0)\n",
    "    final_feature_matrix.to_parquet(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.parquet\", index=True)\n",
    "    print(final_feature_matrix.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab92a44",
   "metadata": {},
   "source": [
    "# Fragment Interval Analysis: Loading Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656ac12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frag_interval_dir = os.path.expanduser('/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/frag_intervals')\n",
    "frag_intervals_results = []\n",
    "for sample in all_samples:\n",
    "    interval_path = os.path.join(frag_interval_dir, '**', f\"{sample}.frag_length_intervals.bed\")\n",
    "    files = glob.glob(interval_path, recursive=True)\n",
    "    if not files:\n",
    "        print(f\"Fragment length Interval file for sample {sample} not found.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(\n",
    "    files[0],\n",
    "    sep=\"\\t\",\n",
    "    header=None,\n",
    "    names=[\"chrom\", \"start\", \"stop\", \"name\", \"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    )\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    group = get_cancer_type(sample)\n",
    "    df['sample'] = sample\n",
    "    df['group'] = group\n",
    "    df[\"start\"] = df[\"start\"].astype(int)\n",
    "    df[\"stop\"] = df[\"stop\"].astype(int)\n",
    "\n",
    "    num_cols = [\"mean\", \"median\", \"stdev\", \"min\", \"max\"]\n",
    "    df[num_cols] = df[num_cols].astype(float)\n",
    "    df['bin'] = df['start'] // BIN_SIZE\n",
    "    frag_intervals_results.append(df)\n",
    "\n",
    "frag_intervals_df = pd.concat(frag_intervals_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a13515a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  chrom    start     stop name        mean  median      stdev    min    max  \\\n",
      "0  chr1   920000   925000    .  166.857143   166.5  19.576433  101.0  224.0   \n",
      "1  chr1  1070000  1075000    .  167.150000   168.5  15.642970  122.0  202.0   \n",
      "2  chr1  1165000  1170000    .  165.625000   163.5  14.876350  131.0  209.0   \n",
      "3  chr1  1170000  1175000    .  168.523077   166.0  14.124836  141.0  217.0   \n",
      "4  chr1  1175000  1180000    .  167.645161   167.5  15.520119  124.0  204.0   \n",
      "\n",
      "    sample     group  bin  \n",
      "0  EE87786  bileduct   18  \n",
      "1  EE87786  bileduct   21  \n",
      "2  EE87786  bileduct   23  \n",
      "3  EE87786  bileduct   23  \n",
      "4  EE87786  bileduct   23  \n"
     ]
    }
   ],
   "source": [
    "print(frag_intervals_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cecf730",
   "metadata": {},
   "source": [
    "# Binning Fragment Interval Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a40f735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean      median      stdev  \\\n",
      "0  EE85723  colorectal  chr1   18  109.333333   64.000000  32.887012   \n",
      "1  EE85723  colorectal  chr1   21  111.000000  111.000000   0.000000   \n",
      "2  EE85723  colorectal  chr1   23   96.250000  100.333333  21.056202   \n",
      "3  EE85723  colorectal  chr1   25  120.750000  120.750000   6.250000   \n",
      "4  EE85723  colorectal  chr1   26   91.666667   89.333333   6.374871   \n",
      "\n",
      "          min         max  \n",
      "0   64.000000  141.000000  \n",
      "1  111.000000  111.000000  \n",
      "2   57.333333  122.333333  \n",
      "3  114.500000  127.000000  \n",
      "4   85.333333  102.666667  \n",
      "(128550, 9)\n"
     ]
    }
   ],
   "source": [
    "binned_df = (\n",
    "    frag_intervals_df.groupby(['sample', 'group', 'chrom', 'bin'])\n",
    "      .agg({\n",
    "          \"mean\": \"mean\",\n",
    "          \"median\": \"mean\",\n",
    "          \"stdev\": \"mean\",\n",
    "          \"min\": \"mean\",\n",
    "          \"max\": \"mean\"\n",
    "      })\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "print(binned_df.head())\n",
    "print(binned_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c14e2739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.00690003889537145)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(binned_df[[\"mean\",\"median\",\"stdev\",\"min\",\"max\"]] == -1).sum()\n",
    "(binned_df[\"mean\"] == -1).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b20d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample     group chrom  bin  wps_value feature_name\n",
      "0  EE87786  bileduct  chr1   18  -0.165352  chr1_bin_18\n",
      "1  EE87786  bileduct  chr1   21  -0.520809  chr1_bin_21\n",
      "2  EE87786  bileduct  chr1   23  -0.041768  chr1_bin_23\n",
      "3  EE87786  bileduct  chr1   25  -0.163598  chr1_bin_25\n",
      "4  EE87786  bileduct  chr1   26  -0.238005  chr1_bin_26\n"
     ]
    }
   ],
   "source": [
    "print(binned_combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd2e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sample       group chrom  bin        mean      median      stdev  \\\n",
      "0  EE85723  colorectal  chr1   18  109.333333   64.000000  32.887012   \n",
      "1  EE85723  colorectal  chr1   21  111.000000  111.000000   0.000000   \n",
      "2  EE85723  colorectal  chr1   23   96.250000  100.333333  21.056202   \n",
      "3  EE85723  colorectal  chr1   25  120.750000  120.750000   6.250000   \n",
      "4  EE85723  colorectal  chr1   26   91.666667   89.333333   6.374871   \n",
      "\n",
      "          min         max  wps_value  \n",
      "0   64.000000  141.000000  -0.091200  \n",
      "1  111.000000  111.000000   0.000000  \n",
      "2   57.333333  122.333333  -0.128733  \n",
      "3  114.500000  127.000000  -0.046586  \n",
      "4   85.333333  102.666667  -0.072200  \n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(\n",
    "    binned_df,\n",
    "    binned_combined_df[['sample', 'chrom', 'bin', 'wps_value']],\n",
    "    how='left',\n",
    "    on=['sample', 'chrom', 'bin']\n",
    ")\n",
    "\n",
    "print(merged_df.head())\n",
    "merged_df.to_csv(f\"/labmed/workspace/lotta/finaletoolkit/ba_analysis_scripts/holdout_preprocessing/dataframes_holdout/final_feature_matrix_{BIN_SIZE}.tsv\", sep=\"\\t\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
